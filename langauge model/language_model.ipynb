{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from spacy.symbols import ORTH\n",
    "from torchtext import data, datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use CUDA: True\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"Use CUDA:\", USE_CUDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhid = 200\n",
    "embed_dim = 300\n",
    "lr = 10\n",
    "NUM_EPOCHS = 20\n",
    "bptt_len = 60\n",
    "batch_size = 32\n",
    "save_path = 'model.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'train.txt'\n",
    "dev_file = 'dev.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_tok = spacy.load('en')\n",
    "def spacy_tok(x):\n",
    "    return [tok.text for tok in lm_tok.tokenizer(x)]\n",
    "\n",
    "TEXT = data.ReversibleField(sequential=True, tokenize=spacy_tok,\n",
    "                            lower=True, include_lengths=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.LanguageModelingDataset(train_file, TEXT, newline_eos=True)\n",
    "dev_dataset = datasets.LanguageModelingDataset(dev_file, TEXT, newline_eos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = \"glove.840B.300d\"\n",
    "TEXT.build_vocab(train_dataset, dev_dataset, vectors=vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterators\n",
    "train_iter = data.BPTTIterator(train_dataset, batch_size=batch_size, bptt_len=bptt_len, repeat=False, shuffle=True)\n",
    "dev_iter = data.BPTTIterator(dev_dataset, batch_size=batch_size, bptt_len=bptt_len, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26246"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings\n",
    "embedding = nn.Embedding(len(TEXT.vocab), embed_dim)\n",
    "embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
    "embedding.weight.requires_grad = False\n",
    "embedding = embedding.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LM(nn.Module):\n",
    "    def __init__(self, ntoken, ninp, nhid, embedding, dropout=0.5):\n",
    "        super(LM, self).__init__()\n",
    "        self.nhid = nhid\n",
    "        self.encoder = embedding\n",
    "        self.rnn = nn.LSTM(ninp, nhid, batch_first=True)\n",
    "        self.decoder = nn.Linear(nhid, ntoken)\n",
    "        self.embed_drop = nn.Dropout(dropout)\n",
    "        self.output_drop = nn.Dropout(dropout)\n",
    "#         self.embed_drop = LockedDropout(dropout)\n",
    "#         self.output_drop = LockedDropout(dropout)\n",
    "\n",
    "#         # # tie weights\n",
    "#         self.decoder.weight = self.encoder.weight\n",
    "\n",
    "    def forward(self, inputs, hidden=None):\n",
    "        \"\"\"\n",
    "\n",
    "        :param inputs: (batch_size, max_len)\n",
    "        :param hidden: ((1, batch_size, nhid), (1, batch_size, nhid))\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        emb = self.embed_drop(self.encoder(inputs))\n",
    "        if hidden:\n",
    "            outputs, hidden = self.rnn(emb, hidden)\n",
    "        else:\n",
    "            outputs, hidden = self.rnn(emb)\n",
    "\n",
    "        outputs = self.output_drop(outputs)\n",
    "        decoded = self.decoder(outputs)\n",
    "        return decoded, outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LM(len(TEXT.vocab), embed_dim, nhid, embedding).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.SGD(lm.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch():\n",
    "    losses = []\n",
    "    for batch in train_iter:\n",
    "        x, y = batch.text.transpose(0, 1).contiguous().to(device), \\\n",
    "                   batch.target.transpose(0, 1).contiguous().to(device)\n",
    "        \n",
    "        out, _, _ = lm(x)\n",
    "        \n",
    "        out = out.contiguous().view(-1, len(TEXT.vocab))\n",
    "        y = y.view(-1)\n",
    "\n",
    "        loss = criterion(out, y).to(device)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # update model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # _ = torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.grad_clipping)\n",
    "        optimizer.step()\n",
    "\n",
    "    return np.exp(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch():\n",
    "    losses = []\n",
    "    for batch in dev_iter:\n",
    "        x, y = batch.text.transpose(0, 1).contiguous().to(device), \\\n",
    "                   batch.target.transpose(0, 1).contiguous().to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out, _, _ = lm(x)\n",
    "        \n",
    "        out = out.contiguous().view(-1, len(TEXT.vocab))\n",
    "        y = y.view(-1)\n",
    "\n",
    "        loss = criterion(out, y).to(device)\n",
    "        losses.append(loss.item())\n",
    "            \n",
    "    return np.exp(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    train_losses = []\n",
    "    dev_losses = []\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        loss_train = train_epoch()\n",
    "        loss_dev = eval_epoch()\n",
    "\n",
    "        print('train perplexity: %.4f, dev perplexity: %.4f' % (loss_train, loss_dev))\n",
    "\n",
    "        train_losses.append(loss_train)\n",
    "        dev_losses.append(loss_dev)\n",
    "        \n",
    "        if loss_dev == min(dev_losses):\n",
    "            torch.save(lm, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = torch.load(save_path)\n",
    "criterion = nn.CrossEntropyLoss(reduction='none').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch():\n",
    "    pairs = []\n",
    "\n",
    "    for i, batch in enumerate(dev_iter):\n",
    "        x, y = batch.text.transpose(0, 1).contiguous().to(device), \\\n",
    "                   batch.target.transpose(0, 1).contiguous().to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out, _, _ = lm(x)\n",
    "        \n",
    "        out = out.contiguous().view(-1, len(TEXT.vocab))\n",
    "        y = y.view(-1)\n",
    "\n",
    "        loss = criterion(out, y).to(device)\n",
    "        loss = loss.view(batch_size, -1)\n",
    "        loss = torch.mean(loss, dim=1)\n",
    "\n",
    "        for ele in zip(x.cpu().numpy(), loss.cpu().numpy()):\n",
    "            pairs.append(ele)\n",
    "\n",
    "    pairs.sort(key=lambda x: x[1])\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = eval_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_sent(indices):\n",
    "    sent = [TEXT.vocab.itos[ele] for ele in indices]\n",
    "    return ' '.join(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "2.4478726\n",
      "far away <eos> do you see signs for the train <eos> they 're a little further away so i ca n't see them <eos> are there trees in the photo <eos> can you tell if this is a male or female <eos> does the dog have long hair or short <eos> what type of vehicle a car truck <eos> no\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "2.472043\n",
      "are they in a box <eos> there is nâ€™t any grass <eos> do they have leaves in their mouth <eos> is there anything else in the scene besides the elephants <eos> can you tell if this is taken in winter time <eos> are there any beverages in scene <eos> i 'm not sure , i do n't see water <eos>\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "2.4836626\n",
      "i think it 's black , but the photo is in black\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "2.5062075\n",
      "might be a couch <eos> can you see any signs or markings <eos> are they standing in line for something <eos> are there other cars in the parking area <eos> it has something in it but i ca n't tell what it is <eos> does this appear to be in a home or a public place <eos> it 's a\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "2.5374718\n",
      "of them <eos> can you see what is inside of them <eos>\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "2.556259\n",
      "is the truck parked along the street <eos> how many people are on this plane <eos> i see the side of it <eos> what type of dog do you think it is <eos> i see what appears to be a partial bottle but i ca n't tell what it is <eos> how many toys are around him <eos> is there\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "2.5647085\n",
      "the giraffes <eos> no he is sitting on the floor <eos> what is the color of the man 's shirt <eos> it 's not really big <eos> what 's the name of the street <eos> what is the gender of the adults <eos> is there anything on top of the stove or is the stew on top already <eos> is\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "2.564771\n",
      "<eos> green and white maybe <eos> are the photographs black and white <eos> no , i ca n't tell at all <eos> no , it is sitting on a piece of furniture <eos> how many people on the elephant <eos> are there people inside the boat <eos> does it look like the sun is shining in <eos> what is on\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "2.58137\n",
      "is the horse facing left or right <eos> i ca n't tell it 's a ground shot <eos> are they the only animals in the scene <eos> are the animals in the wild <eos> is the desk in a house or an office <eos> what kind of bread does it have <eos> do you see any pets around <eos> no\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "2.588656\n",
      "in picture but i think from what i can see he is in his late teens <eos> is the man wearing a hat cap <eos> can you tell the brand of snowboard <eos> brown and gold <eos> no , i only see the bed <eos> does he appear to be outside <eos> are there any other trains in the image\n"
     ]
    }
   ],
   "source": [
    "# good sentences\n",
    "for p in pairs[:10]:\n",
    "    sent, score = p\n",
    "    print('~' * 100)\n",
    "    print(score)\n",
    "    print(indices_to_sent(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "5.798269\n",
      "their jacket <eos> outdoor platform <eos> squash greens <eos> a laptop 3 books an older ipod a bunch of cords a bunch of pens a notebook pill bottles more cords converters , netflix envelopes <eos> yes they look like they are <eos> is suitcase sitting on grass or concrete <eos> is the room well organized <eos> shirt and old pants\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "5.824169\n",
      "the cats have their eyes open <eos> is she in the dirt <eos> has any pieces been taken out <eos> ' before you leave , have you logged off , pushed your chair under desk , tie dyed up , shut down if it is end of day , left room ready for next class <eos> it looks delicious <eos>\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "5.8883324\n",
      "letters and numbers <eos> people are selling different things some have merchandise laying on the ground others appear to be selling popcorn in clear bags the clock tower is about the height of 13 - 15 men it is cream colored with a face that contains latin numbers ike iv , v , x <eos> yes , but i can\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "5.920461\n",
      "real cows <eos> they should be , considering state of disrepair however , amount of moss , vines and general \" shrubbery \" that has grown up around them seem to make me think they will be here for us to cherish for years to come <eos> i can not tell if they do or not <eos> it 's 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "5.9408774\n",
      ", just doors <eos> white with black dials <eos> is the white surface a table <eos> yes but the water is covering it <eos> no , despite very few details surrounding zebra photo is very much alive due to nearly perfect striped coat on zebra he is just trotting along field line with pride <eos> i see 3 couches <eos>\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "6.119509\n",
      "stick out <eos> he has many signs , \" question your government \" \" re - enact glass - steagall banks do n't care about you \" \" brings jobs back ! \" <eos> are people excited <eos> any shepherd <eos> is it a simple stop go light or is there a turn lane <eos> are there people present too\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "6.1966386\n",
      "besides the bird and the pot in the frame <eos> east 34th st <eos> there 's \" cadbury dairy milk triple decker \" chocolate bar and bag labelled \" licorice pieces \" <eos> what color soda cans <eos> decently , i suppose there 's wet floor sign i can see just top of so i think someone recently washed floors\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "6.204807\n",
      "yes , it says american deli market and deli market grocery <eos> s spokane st 3400 is 1 street other is courtland pl s 3600 <eos> not what i can see of it <eos> fairly 1 - 10 scale , solid 7 ^ ^ <eos> what kind of vehicle is it -- car , bus , van , or what\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "6.4846964\n",
      "suite <eos> is he alone in the store <eos> could this cat actually be the boss sitting in his office in charge of a multi million dollar corporation who through clever use of teleconferencing maintain he is actually a billionaire playboy operating his business remotely <eos> is the grass green or dry looking <eos> maybe eating , he is facing\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "8.725532\n",
      "<pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "# bad sentences\n",
    "for p in pairs[-10:]:\n",
    "    sent, score = p\n",
    "    print('~' * 100)\n",
    "    print(score)\n",
    "    print(indices_to_sent(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
